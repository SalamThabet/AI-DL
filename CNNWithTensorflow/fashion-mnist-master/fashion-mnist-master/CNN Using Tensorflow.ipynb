{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "%matplotlib inline\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-2-c16302e8c919>:1: read_data_sets (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n",
      "WARNING:tensorflow:From C:\\Users\\al-khatib\\AppData\\Local\\conda\\conda\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:260: maybe_download (from tensorflow.contrib.learn.python.learn.datasets.base) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please write your own downloading logic.\n",
      "WARNING:tensorflow:From C:\\Users\\al-khatib\\AppData\\Local\\conda\\conda\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:262: extract_images (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/fashion\\train-images-idx3-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\al-khatib\\AppData\\Local\\conda\\conda\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:267: extract_labels (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.data to implement this functionality.\n",
      "Extracting data/fashion\\train-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\al-khatib\\AppData\\Local\\conda\\conda\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:110: dense_to_one_hot (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use tf.one_hot on tensors.\n",
      "Extracting data/fashion\\t10k-images-idx3-ubyte.gz\n",
      "Extracting data/fashion\\t10k-labels-idx1-ubyte.gz\n",
      "WARNING:tensorflow:From C:\\Users\\al-khatib\\AppData\\Local\\conda\\conda\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\contrib\\learn\\python\\learn\\datasets\\mnist.py:290: DataSet.__init__ (from tensorflow.contrib.learn.python.learn.datasets.mnist) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use alternatives such as official/mnist/dataset.py from tensorflow/models.\n"
     ]
    }
   ],
   "source": [
    "data = input_data.read_data_sets('data/fashion',one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(55000, 10)\n",
      "Training set (images) shape: (55000, 784)\n",
      "Training set (labels) shape: (55000, 10)\n",
      "Test set (images) shape: (10000, 784)\n",
      "Test set (labels) shape: (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "# Shapes of training set\n",
    "print(data.train.labels.shape)\n",
    "\n",
    "print(\"Training set (images) shape: {x}\".format(x=data.train.images.shape))\n",
    "print(\"Training set (labels) shape: {shape}\".format(shape=data.train.labels.shape))\n",
    "# Shapes of test set\n",
    "print(\"Test set (images) shape: {shape}\".format(shape=data.test.images.shape))\n",
    "print(\"Test set (labels) shape: {shape}\".format(shape=data.test.labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dictionary of target classes\n",
    "label_dict = {\n",
    " 0: 'T-shirt/top',\n",
    " 1: 'Trouser',\n",
    " 2: 'Pullover',\n",
    " 3: 'Dress',\n",
    " 4: 'Coat',\n",
    " 5: 'Sandal',\n",
    " 6: 'Shirt',\n",
    " 7: 'Sneaker',\n",
    " 8: 'Bag',\n",
    " 9: 'Ankle boot',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5,1,'(Label: Ankle boot)')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=[5,5])\n",
    "\n",
    "# Display the first image in training data\n",
    "plt.subplot(121)\n",
    "\n",
    "curr_img = np.reshape(data.train.images[3], (28,28))\n",
    "curr_lbl = np.argmax(data.train.labels[0,:])\n",
    "plt.imshow(curr_img)\n",
    "plt.title(\"(Label: \" + str(label_dict[curr_lbl]) + \")\")\n",
    "\n",
    "# Display the first image in testing data\n",
    "plt.subplot(122)\n",
    "curr_img = np.reshape(data.test.images[0], (28,28))\n",
    "curr_lbl = np.argmax(data.test.labels[0,:])\n",
    "plt.imshow(curr_img, cmap='gray')\n",
    "plt.title(\"(Label: \" + str(label_dict[curr_lbl]) + \")\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.17254902,\n",
       "       0.49803925, 0.7137255 , 0.7254902 , 0.6313726 , 0.47058827,\n",
       "       0.21568629, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.16470589, 0.77647066, 0.9843138 , 1.        , 0.9843138 ,\n",
       "       0.97647065, 0.9686275 , 1.        , 0.98823535, 0.83921576,\n",
       "       0.3921569 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.00784314, 0.        , 0.        , 0.91372555, 0.98823535,\n",
       "       0.9294118 , 0.93725497, 0.9176471 , 0.9294118 , 0.9215687 ,\n",
       "       0.9294118 , 0.9294118 , 0.9960785 , 0.89019614, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.00392157, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.00784314, 0.        , 0.        ,\n",
       "       0.0627451 , 0.8235295 , 0.882353  , 0.8431373 , 0.6862745 ,\n",
       "       0.85098046, 0.8470589 , 0.7568628 , 0.7686275 , 0.8862746 ,\n",
       "       0.86666673, 0.8196079 , 0.19607845, 0.        , 0.        ,\n",
       "       0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.00784314,\n",
       "       0.        , 0.        , 0.7803922 , 0.8980393 , 0.909804  ,\n",
       "       0.90196085, 0.9607844 , 0.8000001 , 0.8588236 , 0.9921569 ,\n",
       "       0.9607844 , 0.8117648 , 0.7607844 , 0.8745099 , 0.9058824 ,\n",
       "       0.92549026, 0.9215687 , 0.        , 0.        , 0.01176471,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.00392157, 0.        , 0.5372549 ,\n",
       "       0.9215687 , 0.8000001 , 0.8196079 , 0.78823537, 0.8196079 ,\n",
       "       0.9176471 , 0.74509805, 0.9176471 , 0.854902  , 0.8431373 ,\n",
       "       0.9333334 , 0.93725497, 0.8000001 , 0.7411765 , 0.87843144,\n",
       "       0.6039216 , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.7607844 , 0.78823537, 0.7843138 ,\n",
       "       0.8196079 , 0.79215693, 0.7568628 , 0.80392164, 0.7607844 ,\n",
       "       0.7176471 , 0.854902  , 0.9058824 , 0.7725491 , 0.6745098 ,\n",
       "       0.70980394, 0.7568628 , 0.80392164, 0.7803922 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.01176471,\n",
       "       0.8313726 , 0.7960785 , 0.7372549 , 0.7411765 , 0.7686275 ,\n",
       "       0.77647066, 0.77647066, 0.78823537, 0.7686275 , 0.85098046,\n",
       "       0.7019608 , 0.654902  , 0.7176471 , 0.85098046, 0.7725491 ,\n",
       "       0.79215693, 0.8588236 , 0.11764707, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.13333334, 0.882353  , 0.7843138 ,\n",
       "       0.7607844 , 0.74509805, 0.7372549 , 0.75294125, 0.7686275 ,\n",
       "       0.75294125, 0.6666667 , 0.79215693, 0.74509805, 0.78823537,\n",
       "       0.76470596, 0.7843138 , 0.78823537, 0.8196079 , 0.89019614,\n",
       "       0.19607845, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.26666668, 0.882353  , 0.8235295 , 0.82745105, 0.77647066,\n",
       "       0.75294125, 0.7686275 , 0.8000001 , 0.7686275 , 0.70980394,\n",
       "       0.8313726 , 0.7725491 , 0.76470596, 0.75294125, 0.8078432 ,\n",
       "       0.86274517, 0.8235295 , 0.8980393 , 0.3647059 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.43529415, 0.8745099 ,\n",
       "       0.89019614, 0.9921569 , 0.8196079 , 0.7686275 , 0.8000001 ,\n",
       "       0.82745105, 0.8078432 , 0.7176471 , 0.8470589 , 0.8078432 ,\n",
       "       0.8235295 , 0.7960785 , 0.8431373 , 0.9568628 , 0.87843144,\n",
       "       0.89019614, 0.5882353 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.54509807, 0.882353  , 0.87843144, 1.        ,\n",
       "       0.79215693, 0.8078432 , 0.8313726 , 0.8196079 , 0.82745105,\n",
       "       0.74509805, 0.8352942 , 0.79215693, 0.8117648 , 0.8078432 ,\n",
       "       0.8705883 , 1.        , 0.90196085, 0.86274517, 0.74509805,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.7058824 ,\n",
       "       0.8862746 , 0.87843144, 1.        , 0.7803922 , 0.8000001 ,\n",
       "       0.8117648 , 0.83921576, 0.83921576, 0.74509805, 0.8470589 ,\n",
       "       0.8078432 , 0.7960785 , 0.80392164, 0.8588236 , 0.95294124,\n",
       "       0.87843144, 0.83921576, 0.9176471 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.882353  , 0.8745099 , 0.8941177 ,\n",
       "       0.9960785 , 0.8196079 , 0.8078432 , 0.81568635, 0.8352942 ,\n",
       "       0.8235295 , 0.7490196 , 0.8431373 , 0.8117648 , 0.8000001 ,\n",
       "       0.81568635, 0.82745105, 0.97647065, 0.8862746 , 0.83921576,\n",
       "       1.        , 0.14901961, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.9803922 , 0.909804  , 0.94117653, 0.93725497, 0.82745105,\n",
       "       0.7960785 , 0.8196079 , 0.80392164, 0.82745105, 0.7725491 ,\n",
       "       0.8431373 , 0.81568635, 0.81568635, 0.83921576, 0.8352942 ,\n",
       "       0.93725497, 0.9058824 , 0.8588236 , 1.        , 0.31764707,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.9725491 , 0.92549026,\n",
       "       0.9686275 , 0.94117653, 0.7960785 , 0.7843138 , 0.81568635,\n",
       "       0.8078432 , 0.83921576, 0.7568628 , 0.8352942 , 0.8313726 ,\n",
       "       0.81568635, 0.8313726 , 0.82745105, 0.95294124, 0.9490197 ,\n",
       "       0.882353  , 0.9960785 , 0.25882354, 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.9686275 , 0.90196085, 0.98823535, 0.8862746 ,\n",
       "       0.7803922 , 0.82745105, 0.79215693, 0.82745105, 0.8352942 ,\n",
       "       0.7137255 , 0.8352942 , 0.8313726 , 0.8078432 , 0.79215693,\n",
       "       0.8588236 , 0.8117648 , 0.9686275 , 0.8705883 , 0.9294118 ,\n",
       "       0.40784317, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.03921569, 0.9568628 ,\n",
       "       0.8588236 , 0.9803922 , 0.80392164, 0.7803922 , 0.8196079 ,\n",
       "       0.79215693, 0.8196079 , 0.82745105, 0.7411765 , 0.83921576,\n",
       "       0.8078432 , 0.8235295 , 0.7843138 , 0.8313726 , 0.6039216 ,\n",
       "       0.94117653, 0.81568635, 0.8588236 , 0.54901963, 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.08235294, 1.        , 0.8705883 , 0.9333334 ,\n",
       "       0.72156864, 0.8235295 , 0.75294125, 0.8078432 , 0.8196079 ,\n",
       "       0.8235295 , 0.7411765 , 0.8352942 , 0.82745105, 0.8196079 ,\n",
       "       0.75294125, 0.8941177 , 0.60784316, 0.8862746 , 0.9333334 ,\n",
       "       0.9450981 , 0.6509804 , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.14509805,\n",
       "       0.9607844 , 0.8862746 , 0.9450981 , 0.5882353 , 0.7725491 ,\n",
       "       0.7411765 , 0.8000001 , 0.8196079 , 0.8235295 , 0.7176471 ,\n",
       "       0.8352942 , 0.8352942 , 0.78823537, 0.72156864, 0.8431373 ,\n",
       "       0.57254905, 0.8470589 , 0.92549026, 0.882353  , 0.6039216 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.227451  , 0.93725497, 0.89019614,\n",
       "       1.        , 0.61960787, 0.7568628 , 0.76470596, 0.8000001 ,\n",
       "       0.8196079 , 0.8352942 , 0.7058824 , 0.8117648 , 0.85098046,\n",
       "       0.7803922 , 0.7607844 , 0.82745105, 0.61960787, 0.8588236 ,\n",
       "       0.92549026, 0.8470589 , 0.5921569 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.26666668, 0.91372555, 0.8862746 , 0.95294124, 0.54509807,\n",
       "       0.7843138 , 0.7568628 , 0.80392164, 0.8235295 , 0.81568635,\n",
       "       0.7058824 , 0.80392164, 0.8313726 , 0.7960785 , 0.7686275 ,\n",
       "       0.8470589 , 0.6156863 , 0.7019608 , 1.        , 0.8470589 ,\n",
       "       0.60784316, 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.31764707, 0.882353  ,\n",
       "       0.87843144, 0.82745105, 0.5411765 , 0.8588236 , 0.7254902 ,\n",
       "       0.78823537, 0.8352942 , 0.8117648 , 0.7725491 , 0.8862746 ,\n",
       "       0.8313726 , 0.7843138 , 0.74509805, 0.8431373 , 0.7176471 ,\n",
       "       0.3529412 , 1.        , 0.82745105, 0.5764706 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.35686275, 0.8235295 , 0.90196085, 0.61960787,\n",
       "       0.44705886, 0.80392164, 0.73333335, 0.81568635, 0.8196079 ,\n",
       "       0.8078432 , 0.7568628 , 0.8235295 , 0.82745105, 0.8000001 ,\n",
       "       0.76470596, 0.8000001 , 0.70980394, 0.09019608, 1.        ,\n",
       "       0.8352942 , 0.61960787, 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.34117648,\n",
       "       0.80392164, 0.909804  , 0.427451  , 0.6431373 , 1.        ,\n",
       "       0.83921576, 0.87843144, 0.8705883 , 0.8235295 , 0.7725491 ,\n",
       "       0.83921576, 0.882353  , 0.8705883 , 0.82745105, 0.86274517,\n",
       "       0.85098046, 0.        , 0.9176471 , 0.8470589 , 0.6627451 ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.36078432, 0.8352942 , 0.909804  ,\n",
       "       0.57254905, 0.01960784, 0.5254902 , 0.5921569 , 0.63529414,\n",
       "       0.6666667 , 0.7176471 , 0.7137255 , 0.6431373 , 0.6509804 ,\n",
       "       0.69803923, 0.63529414, 0.6117647 , 0.38431376, 0.        ,\n",
       "       0.94117653, 0.882353  , 0.8235295 , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.16862746, 0.6431373 , 0.8078432 , 0.5529412 , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.49803925, 0.4901961 ,\n",
       "       0.29803923, 0.        , 0.        , 0.        ], dtype=float32)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.train.images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(data.train.images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(data.train.images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape training and testing image\n",
    "train_X = data.train.images.reshape(-1, 28, 28, 1)\n",
    "test_X = data.test.images.reshape(-1,28,28,1)\n",
    "train_X = train_X[0:7000]\n",
    "test_X = test_X[0:1000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7000, 28, 28, 1), (1000, 28, 28, 1))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, test_X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y = data.train.labels\n",
    "test_y = data.test.labels\n",
    "train_y = train_y[0:7000]\n",
    "test_y = test_y[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7000, 10), (1000, 10))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.shape, test_y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_iters = 200 \n",
    "learning_rate = 0.001 \n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST data input (img shape: 28*28)\n",
    "n_input = 28\n",
    "\n",
    "# MNIST total classes (0-9 digits)\n",
    "n_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#both placeholders are of type float\n",
    "x = tf.placeholder(\"float\", [None, 28,28,1])\n",
    "y = tf.placeholder(\"float\", [None, n_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d(x, W, b, strides=1):\n",
    "    # Conv2D wrapper, with bias and relu activation\n",
    "    x = tf.nn.conv2d(x, W, strides=[1, strides, strides, 1], padding='SAME')\n",
    "    x = tf.nn.bias_add(x, b)\n",
    "    return tf.nn.relu(x) \n",
    "\n",
    "def maxpool2d(x, k=2):\n",
    "    return tf.nn.max_pool(x, ksize=[1, k, k, 1], strides=[1, k, k, 1],padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = {\n",
    "    'wc1': tf.get_variable('W0', shape=(3,3,1,32), initializer=tf.contrib.layers.xavier_initializer()), \n",
    "    'wc2': tf.get_variable('W1', shape=(3,3,32,64), initializer=tf.contrib.layers.xavier_initializer()), \n",
    "    'wc3': tf.get_variable('W2', shape=(3,3,64,128), initializer=tf.contrib.layers.xavier_initializer()), \n",
    "    'wd1': tf.get_variable('W3', shape=(4*4*128,128), initializer=tf.contrib.layers.xavier_initializer()), \n",
    "    'out': tf.get_variable('W6', shape=(128,n_classes), initializer=tf.contrib.layers.xavier_initializer()), \n",
    "}\n",
    "biases = {\n",
    "    'bc1': tf.get_variable('B0', shape=(32), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'bc2': tf.get_variable('B1', shape=(64), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'bc3': tf.get_variable('B2', shape=(128), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'bd1': tf.get_variable('B3', shape=(128), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "    'out': tf.get_variable('B4', shape=(10), initializer=tf.contrib.layers.xavier_initializer()),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_net(x, weights, biases):  \n",
    "\n",
    "    # here we call the conv2d function we had defined above and pass the input image x, weights wc1 and bias bc1.\n",
    "    conv1 = conv2d(x, weights['wc1'], biases['bc1'])\n",
    "    # Max Pooling (down-sampling), this chooses the max value from a 2*2 matrix window and outputs a 14*14 matrix.\n",
    "    conv1 = maxpool2d(conv1, k=2)\n",
    "\n",
    "    # Convolution Layer\n",
    "    # here we call the conv2d function we had defined above and pass the input image x, weights wc2 and bias bc2.\n",
    "    conv2 = conv2d(conv1, weights['wc2'], biases['bc2'])\n",
    "    # Max Pooling (down-sampling), this chooses the max value from a 2*2 matrix window and outputs a 7*7 matrix.\n",
    "    conv2 = maxpool2d(conv2, k=2)\n",
    "\n",
    "    conv3 = conv2d(conv2, weights['wc3'], biases['bc3'])\n",
    "    # Max Pooling (down-sampling), this chooses the max value from a 2*2 matrix window and outputs a 4*4.\n",
    "    conv3 = maxpool2d(conv3, k=2)\n",
    "\n",
    "\n",
    "    # Fully connected layer\n",
    "    # Reshape conv2 output to fit fully connected layer input\n",
    "    fc1 = tf.reshape(conv3, [-1, weights['wd1'].get_shape().as_list()[0]])\n",
    "    fc1 = tf.add(tf.matmul(fc1, weights['wd1']), biases['bd1'])\n",
    "    fc1 = tf.nn.relu(fc1)\n",
    "    # Output, class prediction\n",
    "    # finally we multiply the fully connected layer with the weights and add a bias term. \n",
    "    out = tf.add(tf.matmul(fc1, weights['out']), biases['out'])\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-24-d62051f3459b>:3: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See @{tf.nn.softmax_cross_entropy_with_logits_v2}.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pred = conv_net(x, weights, biases)\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=pred, labels=y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Here you check whether the index of the maximum value of the predicted image is equal to the actual labelled image. and both will be a column vector.\n",
    "correct_prediction = tf.equal(tf.argmax(pred, 1), tf.argmax(y, 1))\n",
    "\n",
    "#calculate accuracy across all the given images and average them out. \n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0, Loss= 0.543837, Training Accuracy= 0.81250\n",
      "Optimization Finished!\n",
      "Testing Accuracy: 0.73600\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-6137a5f61180>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     13\u001b[0m                 \u001b[1;31m# Calculate batch loss and accuracy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m             opt = sess.run(optimizer, feed_dict={x: batch_x,\n\u001b[1;32m---> 15\u001b[1;33m                                                               y: batch_y})\n\u001b[0m\u001b[0;32m     16\u001b[0m             loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,\n\u001b[0;32m     17\u001b[0m                                                               y: batch_y})\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1320\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1324\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1305\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1309\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\conda\\conda\\envs\\deeplearning\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1407\u001b[0m       return tf_session.TF_SessionRun_wrapper(\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1411\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_exception_on_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(init) \n",
    "    train_loss = []\n",
    "    test_loss = []\n",
    "    train_accuracy = []\n",
    "    test_accuracy = []\n",
    "    summary_writer = tf.summary.FileWriter('./Output', sess.graph)\n",
    "    for i in range(training_iters):\n",
    "        for batch in range(len(train_X)//batch_size):\n",
    "            batch_x = train_X[batch*batch_size:min((batch+1)*batch_size,len(train_X))]\n",
    "            batch_y = train_y[batch*batch_size:min((batch+1)*batch_size,len(train_y))]    \n",
    "            # Run optimization op (backprop).\n",
    "                # Calculate batch loss and accuracy\n",
    "            opt = sess.run(optimizer, feed_dict={x: batch_x,\n",
    "                                                              y: batch_y})\n",
    "            loss, acc = sess.run([cost, accuracy], feed_dict={x: batch_x,\n",
    "                                                              y: batch_y})\n",
    "        print(\"Iter \" + str(i) + \", Loss= \" + \\\n",
    "                      \"{:.6f}\".format(loss) + \", Training Accuracy= \" + \\\n",
    "                      \"{:.5f}\".format(acc))\n",
    "        print(\"Optimization Finished!\")\n",
    "\n",
    "        # Calculate accuracy for all 10000 mnist test images\n",
    "        test_acc,valid_loss = sess.run([accuracy,cost], feed_dict={x: test_X,y : test_y})\n",
    "        train_loss.append(loss)\n",
    "        test_loss.append(valid_loss)\n",
    "        train_accuracy.append(acc)\n",
    "        test_accuracy.append(test_acc)\n",
    "        print(\"Testing Accuracy:\",\"{:.5f}\".format(test_acc))\n",
    "    summary_writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i love you do you love me salam i love ypu "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i love you too "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
